len(Doc.structure): 8 Doc.title: None
len(DocSection.structure): 0 DocSection.title: None lvl: None
определения, обозначения и сокращения токен – единица текста, обычно представляет собой несколько букв или слово. токенизация – процесс преобразования исходного текст в последовательность токенов. референсная транскрипция – истинная транскрипция аудиофрагмента с речью, чаще всего получена с помощью людей-разметчиков искуственная нейронная сеть (нейросеть) – математическая модель, в некотором ходе схожая с нейронными сетями живых организмов. диффузионные модели — это класс моделей скрытых переменных, которые обучаются итеративно преобразовывать случайный гауссовский шум, который может быть сгенерирован аналитически, в наблюдения из данных с неизвестным распределением [8]. автокодировщик  – класс искуственных нейронных сетей, который используется для получения оптимальных векторных представлений каких-либо данных [4] лосс функция (функция потерь) – дифференцируемая функция, которая  даёт некоторую оценку на разницу между истинным ответом и предсказанием модели эмбеддинг — векторое представление, полученное с помощью нейросети, чаще всего представляет собой промежуточное значение с какого-либо слоя нейросети прямого распространения — один из простейших видов нейростей, состоит из матричных умножений и нелинейных функций активации мультиголовый механизм самовнимания (multi-head self-attention) — один из типов слоёв искуственных нейронных сетей, предложенный в статье attention is all you need [9] леернорм (layernorm) — один из типов слоёв искуственных нейронных сетей, выполняет нормировку входных данных по оси признаков, содержит два обучаемых параметра — разброс и смещение [24] датасет — набор размеченных данных тренировочный датасет (трейнсет) — датасет, используемый на этапе обучения модели валидационный датасет (валсет) — датасет, используемый на этапе оценки модели, примеры из него строго не должно содержаться в тренировочном датасете функция активации — нелинейная функция, используемая между линейными и квазилинейный преобразованиями в нейронных сетях с целью улучшения обощающей способности self-supervised — способ обучения нейронной сети, в условиях малого количества размеченных данных, где сначала модель обучается на имеющихся размеченных данных, после чего используется для генерации разметки на неразмеченных данных, после чего полученная разметка используется для обучения следующей модели и так далее свёрточный слой — один из типов слоёв искусственных нейронных сетей, вычисляет операцию свёртки между входными данными и фильтром, фильтр является обучаемым параметром трансформер — архитектура искусственной нейронной сети, предложенная в статье [9], построенная на использовании  multi-head self-attention n-грамма — некоторое множество грамматических единиц текста, например, букв, слов или токенов кодбук — заранее заданное множество векторов, чаще всего ортогональных, иногда кодбуки бывают обучаемыми батч — множество объектов, представленных в виде матрицы или тензора большей размерности, используемых на одном прогоне модели кросс-аттеншен — один из типов слоёв искусственых нейронных сетей, где механизм самовнимание получает в качестве key и query векторов данные из различных последовательностей аугментации — различные незначительные преобразование входных данных, помогающие разнообразить обучающий датасет модели и увеличить её обощающую способность позиционные эмбеддинги — специальная добавка ко входным данным модели, которая кодирует информацию о позиции элемента в последовательности

len(DocSection.structure): 0 DocSection.title: введение lvl: 2
в последнее время резко возросла потребность в распознавании речи в большом количестве сценариев. задача перевод речи в текст возникает в системах видеоконференцсвязи, системах голосового управление и многих других. также в последнее время большое развитие получили нейросетевые подходы к задаче распознавания, которые показывают лучшие результаты среди всех алгоритмов-конкурентов. одним из новых типов искуственных нейронных сетей являются диффузионные модели, хорошо показавшие себя в нескольких классах задач. всё это приводит к потребности в исследовании диффузионных моделей в задаче распознавания речи цель работы: исследовать потенциал использования диффузионных моделей в задаче распознавания речи объектом исследования является диффузионные нейросетевые модели распознавания речи предметом исследования является применимость нейросетевых алгоритмов, основанных на диффузии в непрерывных пространствах, в распознавании речи для достижения поставленной цели требуется решить следующие задачи: 1. анализ существующих решений 2. выбор используемых методов 3. реализация и обучения диффузионной модели 4. оценка качества и сравнение с аналогами

len(DocSection.structure): 2 DocSection.title: 1. актуальность lvl: 2
в современном мире большое количество информации представлено в аудиоформате и количество такой информации продолжает расти с каждым днём. источниками такой информации могут послужлить системы телефонии, видеосвязи, стриминговые сервисы, а также множество других. с ростом количества аудиоданных усложняется работа с ними на многих уровнях. начиная со скорости восприятия информации — для человека намного быстрее прочитать транскрипцию, чем прослушать аудио — заканчивая более сложными задачами, по типу текстового поиска и составления краткого содержания. всё это приводит к увеличению потребности в продвинутых системах распознавания речи. в настоящее время уже проведен ряд исследований в этой области, а также разработаны работоспособные системы. однако ошибка таких систем не равна нулю, что вызывает потребность в проведении дальнейших исследований в этой области. основным подходом к задаче распознавания речи является использования машинного обучения, а конкретно — глубокого обучения. глубокое обучение — раздел машинного обучения, занимающийся изучением и применением многослойных нейронных сетей. в последние годы эта область человеческого знания активно развивается, предлагаются новые подходы и методы по созданию нейросетевых алгоритмов. такие алгоритмы хорошо показывают себя на большом классе задач — распознавание речи, сегментации изображений, генерации текста и фото. одним из последних достижений науки являются диффузионные модели, хорошо показавшие себя в задачах генерации изображений и речи [1], [2].
  len(DocSection.structure): 0 DocSection.title: 1.1 применение систем распознавания речи в современном мире lvl: 3
  как было сказано ранее, количество аудио контента, производимого человечеством позволяет расти, а работа с его содержанием путём прослушиванию вызывает всё больше трудностей. также распознавать речь требуется не только в задачах, связанных с обработкой или поиском информации человеком, но и в задачах создания голосовых интерфейсов управления. ниже представлен список возможных применений систем распознавания речи: 1. видеоконференции в ходе пандемии covid-19, а также нескольких последующих лет сильно возрасло количество вкс, а также их аудитория. такие системы используются в большом количестве организаций — корпорациях, образовательных и государственных учреждениях, сотрудники пользуются видеосвязью для проведения совещаний, лекций, планирований и иных встреч. часто, в результате таких встреч требуется составить протокол встречи, чтобы после можно было вернуться к нему и получить доступ к информацию с прошедей встречи. 2. телефония в большом количестве компанию существуют отделы продаж и технической поддержки, активно использующие в своей работе телефонную связь. информация о содержании разговоров сотрудников может потребоваться для улучшения качество облуживания клиентов и проведения речевой аналитики. 3. переводчики ещё одним применением распознавания речи могут служить системы перевод. большинство современных систем перевода работают на уровне текста, поэтому в сценарии, когда пользователь переводчика не знает языка и имеет доступ только к аудио информации, системы распознавания могут помочь ему с перевод аудио в текст для дальнейшего перевода на другой язык 4. голосовые ассистенты также распознавание речи может быть необходимо в голосовых ассистенах для понимания команд и запросов пользователя, озвученных голосом

  len(DocSection.structure): 0 DocSection.title: 1.2 обоснование использования диффузионных моделей в задаче распознавания речи lvl: 3
  за небольшое количество времени диффузионные модели показали впечатляющие результаты в работе с изображениями и синтезе речи, а также нашли применение в генерации текста. это позволяет ожидать, что и из их применения в задаче распознавания речи получится извечь выгоду


len(DocSection.structure): 2 DocSection.title: 2. обзор аналогов lvl: 2
в этом разделе будут рассмотрены существующие подходы к задаче распознавания речи. перед тем, как перейти к рассмотрению аналогов опишем задачу распознавания речи формально — на вход поступает цифровой аудиосигнал, а результатом является текст на каком-либо языке. таким образом: x — входной вектор размером t, где t — количество дискретных измерений l — референсная транскрипция для аудиозаписи x задача состоит в том, чтобы найти отображение из пространства x в пространство l. так как данная задача не имеет аналитического решения в общем виде принято использовать различные модели, которые стараются оценить и аппроксиморовать данное отображение.
  len(DocSection.structure): 0 DocSection.title: 2.1 ctc — подходы lvl: 3
  connectionist temporal classification (ctc) — метод при обучении нейронных сетей на задачу матчинга последовательностей без знания точного временного соответсвия между элементами последовательности. обычно данный метод используется в задаче распознавания речи или задачи распознавания рукописного текста. метод был предложен в 2006 году алексом грейсвом и его коллегами [22]. для описания метода введём обозначения: x — входная последовательность из векторов размерности m t — длина последовательности x l — алфавит из элементов которого состоит выходная последовательность y — выходная последовательность, состоящая из элементов l бланк (<blank>) — специально добавляемый символ алфавита, используется на декодировании l` — алфавит l, к которому добавили бланк n — мощность алфавита l` алгоритм получаем на вход один вектор из m значений, а на выход выдаёт вероятностное распределение над алфавитом l`. в ходе обработки всей последовательности x, получается t вероятностых распределений над l`, обозначим их как матрицу a размера n на t. введём понятие пути. путь — это последовательность элементов матрицы a, которая однозначно определяет выходную последовательность z. для такого пути (обозначием его l) можно построить оценку его вероятности, согласно следующей формуле: , где i — номер элемента выходной последовательности l(i) — индекс в алфавите элемента, находящегося на позиции i в выходной последовательности p(y|x) — вероятность получить выходную последовательность x, при входной последовательности y. на этапе обучения нейронной сети есть набор (d) размеченных пар (x,y) — в данном случае аудио и речь. тогда на обучении алгоритм будет по последовательности x генерировать матрицу вероятностей a, согласно которой будут рассчитываться оценки вероятностей для референсных транскрипций. на основе этих оценок будем считать следующую лосс-функцию: которую будем оптимизировать с помощью изменения параметров модели. однако при таком подходе есть проблема с распознаванием идущих подряд одинаковых элементов выходной последовательности. допустим, есть два соседних, с точки зрения времени, распределения, максимальную вероятность в которых имеет один и тот же элемент. в такой ситуации нельзя разделить ситуации — один элемент на несколько временных отрезков или это два одинаковых элемента на соседних временных отрезках.  в задаче распознавания речи это наглядно видно в словах с повторяющимися буквами. например, слово «стресс». для разделения таких случаев и вводится бланк символ. он вставляется между одинаковыми элементами алфавита и означает переход к следующему символу.  тогда последовательности вида: {с, т, р, е, с, <blank>, с} будут переводится в «стресс», а последовательности вида {с, т, р, е, с, с}, будут приводится к виду «стресс». на представленном ниже рис. 1 можно видеть пример работы ctc: рисунок 1 – пример ctc на этапе получения выходной последовательности. по вертикали расположены элементы выходной последовательности, а по горизонтали входной. глубина цвета означает вероятность, эпсилон — это бланк-символ примером модели, обученной с помощью ctc может служить нейросеть с архитектурой conformer [19]. conformer — одна из первых удачных попыток совмещения свёртночных нейронных сетей и механизма самовнимания в задаче распознавания речи. архитектура conformer представлена на рис. 2. рисунок 2 – архитектура conformer в начале модели идёт блок «convolution subsampling», который сжимает размер входной последовательности в 4 раза, что уменьшает требуемое количество вычислений. далее следует последовательность из «conformer block»-ов - основного модуля этой архитектуры, состоящего из свёрток, сетей прямого распространения и механизма самовнимания, а также леернормов. визуализацию «conformer block» можно видеть на рис. 2.

  len(DocSection.structure): 4 DocSection.title: 2.2 transfusion lvl: 3
  это диффузионная модель для распознавания речи, предложенная в статье [3]. основная идея — обучить модель текстовой диффузии, у которой диффузионный процесс может быть обусловлен на вектороное представление аудио, содержащего человеческую речь.
    len(DocSection.structure): 0 DocSection.title: 2.2.1 мультиноминальная диффузия lvl: 4
    обычно диффузионные модели работают с вещественными представлениями данные, это могут быть эмбеддинги, картинки или спектрограммы. однако текст имеет дискретную природу, поэтому авторы используют мультиноминальную диффузию предложенную в статье [15]. конкретно мультиномильная диффузия определяется входы диффузионной модели, как последовательность дискретных элементов (символов или слов), представленных в виде векторов содержащих одну единицу, а остальное заполнено нулями. формальные обозначения: - индекс временного шага, t — количество временных шагов - индекс позиции в последовательности - вектора, представляющие элементы последовательности, размерность векторов совпадает с мощностью алфавита символов мультиноминальная диффузия определяет прямой процесс диффузии следующим образом: , c обозначает категориальное распределение, - коэффициент расписания добавления шума, таким образом предиктор шума предсказывает на каждой итерации диффузии распределение над словарём

    len(DocSection.structure): 0 DocSection.title: 2.2.2 получение векторных представлений аудио lvl: 4
    для получения аудиоэмбеддингов авторы используют предобученную модель wavlm [16]. данная модель обучалась на огромном количестве данных в self-supervised режиме, что позволило достичь высокой обобщающей способности внутренних представлений модели. во время обучения предсказателя шума авторы не изменяют параметры wavlm, эмбеддинги строятся для каждых 20 миллисекунд исходного аудио. модель содержит порядка 317 миллионов параметров и обучалась на данных объёмом порядка 94 тысяч часов.

    len(DocSection.structure): 0 DocSection.title: 2.2.3 архитектура модели lvl: 4
    в качестве предсказателя шума авторы используют архитектуру нейросети на основе трансформера. для обуславливания процесса диффузии на содержаниие аудио авторы добавляют небольшой блок состоящий из линейных проекций, нормировок и нелиненых функций активации. всего сеть содержит 24 трансформер-блока и имеет 253 миллиона параметров, архитекутра представлена на рис. 3. рисунок 3 – архитектура предсказателя шума

    len(DocSection.structure): 0 DocSection.title: 2.2.4 обучение модели lvl: 4
    лосс функция, используемая авторами также берётся из статьи [15]. так как основная цель при обучении диффузионной модель — это построение модели, которая будет предсказывать  максимально близкое к апостериорному распределению , то в качестве лосс-функции используется дивергенция кульбака-лейблера: при обучении используется 200 временных шагов диффузии, аудиоэмбеддинги из wavlm-large, используется оптимизатор adamw [25] со значениями бет (0.9, 0.999) и с константным расписанием обучающих коэффициентов с разогревом 10000 итераций и пиковым значением . в качестве обучающего датасета используется librispeech-960h, аугментации не используются.



len(DocSection.structure): 11 DocSection.title: 3. теоретическая часть lvl: 2

  len(DocSection.structure): 3 DocSection.title: 3.1 обзор предметной области lvl: 3
  в данном разделе описан ряд понятий, используемых в большом количестве работ, а также при описании предлагаемого в данной работе решения.
    len(DocSection.structure): 0 DocSection.title: 3.1.1 формальная постановка задачи lvl: 4
    на вход поступает аудиосигнал, содержащий один канал, который может быть представлен в виде вещественных или натуральных чисел. в общем случае аудио сигнал представляет собой вектор из , где n — количество отсчётов, полученных при дискретизации аналогового сигнала. на выход поступает последовательность из элементов из заранее известного конечного алфавита.

    len(DocSection.structure): 0 DocSection.title: 3.1.2 метрики качества lvl: 4
    в задаче распознавания речи сущесвует огромное количество метрик, который пытаются оценивать те или иные аспекты качества. в данной работе будет использоваться метрика wer (word error rate), основанная на расстоянии левенштейна. , где s — количество замен, d — количество ударений, i — количество вставок, а n — количество слов во референсной транскрипции в задаче оценки генерации текста с помощью автокодировщика используются метрики rouge-1, rouge-l и bleu. расчёт rouge-1 производится, согласно следующим формулам: , где в числителе — количество общих юниграмм в референсном тексте и в полученном, а в знаменателе — количество юниграмм в референсном тексте , где в числителе — количество общих юниграмм в референсном тексте и в полученном, а в знаменателе — количество юниграмм в сгенерированном тексте расчёт rouge-l производится, согласно следующим формулам: , где доп — длиннейшая общая подпоследовательность расчёт bleu [7] производится, согласно следующим формулам: , где c — длина сгенерированного текста, r — «эффективная» длина референсного текста - вес для данной n-граммы , где count — количестве слов в n-грамме maxrefcount — максимальное количество слов в референсной транскрипции

    len(DocSection.structure): 0 DocSection.title: 3.1.3 предобработка аудиоданных lvl: 4
    зачастую, работать напрямую с аудиосигналом неудобно — это приводит обработке очень длинных последовательностей, что усложняет вычисления. кроме того, представление в виде сырого аудиосигнала может быть не очень инфомативным в задаче распознавания речи. одним из самых распространённых представлений аудиосигнала является лог-мел-спектрограмма. спектограмма — это визуальное представление зависимости спектральной плотности мощности сигнала от времени, получаемое с помощью оконного преобразования фурье. пример такого представления можно видеть на рис. 4. формула для расчёта интенстивности: , где t — время w — частота stft — оконное преобразование фурье рисунок 4 – спектрограмма лог-спектрограмма — это спектрограмма, значения интенсивности которой отложены в децибелах. пример такой спектрограммы можно видеть на рис. 5. рисунок 5 – лог-спектрограмма лог-мел-спектрограмма — это лог-спектрограмма, частоты которой преобразованы специальным образом. мел-шкала создана в связи с тем, что люди нелинейно воспринимают разницу между частотами в разных диапазонах. для перевода значений в мел-шкалу используется следующая формула: пример такой спектрограммы можно видеть на рис. 6. рисунок 6 – лог-мел-спектрограмма


  len(DocSection.structure): 0 DocSection.title: 3.2 спектральные аугментации (specaug) lvl: 3
  одним из самых простых и эффективных способов аугментации спектрограмм являются спектральные аугментации [26]. пусть у нас есть спектрограмм в границах по оси времени и по оси частоты, тогда спектральная аугментация это процесс в ходе которого выделяется случай отрезов спектрограммы по одной из осей и удаляется. рисунок 7 – пример результата применения спектральных аугментаций на рис. 7 можно чётко видеть «вырезанные» области прямоугольного цвета, которые были заполнены нулями. аугментации такого типа не позволяют моделям переобучаться на те или иные частоты и делают их более устойчивыми к кратковременным помехам или потерям сигнала.

  len(DocSection.structure): 2 DocSection.title: 3.3 диффузионные модели lvl: 3
  диффузионные модели — это класс моделей скрытых переменных, которые обучаются итеративно преобразовывать случайный гауссовский шум, который может быть сгенерирован аналитически, в наблюдения из данных с неизвестным распределением. этот класс моделей был впервые предложен в статье в 2015 году [8]
    len(DocSection.structure): 0 DocSection.title: 3.3.1 прямой процесс диффузии lvl: 4
    прямой процесс диффузии — процесс зашумления исходного наблюдения с помощью добавление нормального шума. данный алгоритм получает на вход некое наблюдение из реальных данных - , после чего начинается добавлять небольше количество нормального шума. после повторения такой операции t раз получается последовательносить замушлённых наблюдений . добавление шума параметризовано с помощью коэффициентов . в ходе такого процесса исходное наблюдение  с каждым шагом теряет всё больше данных и содержит всё меньше информации об исходном объекте. причём для вычисления зашумлённого x на произвольном шаге не требуется вычислять все промежуточные шаги так как легко можно репараметризовать формулу, введя обозначения  и

    len(DocSection.structure): 0 DocSection.title: 3.3.2 обратный процесс диффузии lvl: 4
    обратный процесс диффузии — процесс восстановление исходного наблюдений по его зашумлённому состоянию. для построения точной оценки  требуется весь набор данных, что является трудновыполнимым условием, поэтому для этой задачи обучается модель , способная аппроксимировать эти условные вероятности и запустить обратный процесс диффузии. для этого нужно обучить модель для предсказания однако значение известно нам на обучении, поэтому можно предсказывать сразу добавленный шум . в статье [ссылка на папиру про упрощения лосса] эмпирически обнаружено, что диффузионные модели лучше работают при обучении с лоссом:


  len(DocSection.structure): 0 DocSection.title: 3.4 архитектура трансформер lvl: 3
  трансформер — одна из самых популярных архитектур нейронных сетей, основанная на muti-head self-attention, была предложена в статье 2017 года [9]. трансформер состоит из двух больших блоков, которые идентичны между собой — энкодер и декодер. разница лишь в аттеншен маска т.е к каким токенам имеется доступ при вычислении multi-head self-attention. энкодер и декодер состоят, в свою очередь, из multi-head self-attention и небольших сетей прямого распространения, пример блока изображён на рис. 8. рисунок 8 – высокоуровневое представление одного трансформер-блока здесь - эмбеддинги элементов последовательности, которую обрабатывает трансформер. на первом слое такие эмбеддинги берутся из специального словаря, который хранит споставления (уникальный элемент, его эмбеддинг), а далее такие эмбеддинги получаются в ходе работыть предыдущих трансформер-блоков. внутри multi-head self-attenion есть три матрицы проекций: query (запросы) key (ключи) values (значения) по входному эмбеддингу вычисляются его query, key и value с помощью этих матриц проекций. далее query вектора каждого элемента умножаются на каждый элемент key векторов каждого элемента, в результате чего получается некий «вес», который каждый элемент присваивает всем остальным элементам. после эти веса нормируются и используются для взвешенной суммы value векторов, которые становятся новыми эмбеддингами. в матричном виде эти преобразования можно записать следующим образом: , где q — значения query векторов k — значения key векторов v — значения value векторов d — внутрення размерность модели причем таких наборов матриц проекций строится несколько, каждый такой набор называется «головой» self-attention

  len(DocSection.structure): 0 DocSection.title: 3.5 автокодировщик lvl: 3
  автокодировщик  – класс искуственных нейронных сетей, который используется для получения оптимальных векторных представлений каких-либо данных, предложенный в [4]. архитектура таких моделей выглядит следующим образом	: энкодер — нейронная сеть, которая получает на вход данные в исходном пространстве и выполняет ряд преобразований, в результате которых получает новое представление данных в латентном пространстве, размерность которого существенно меньше размерности представления в исходном пространстве декодер — нейронная сеть, которая получает на вход векторное представление из латентного пространства и восстанавливает исходный объект в исходном пространстве изображение архитектуры в общем виде можно видеть на рис. 9. рисунок 9 – общий вид архитектуры автокодировщика для обучения таких моделей требуется ввести лосс функцию реконструкции, например, среднеквадратичную ошибку между входным вектором и результатом работы декодера то есть результатом восстановления наблюдения из полученного латентного представления.

  len(DocSection.structure): 0 DocSection.title: 3.6 latent diffusion for language generation lvl: 3
  в этой статье [21] авторы обучают текстовую диффузию для задачи генерации текста. для этого они используют несколько предобученных sequence-to-sequence моделей (bart и t5). предлагаемый метод состоит из двух основных частей: 1. расширяют преодбученную языковую модель для получения автокодировщика текста 2. предлагают модели непрерывной диффузии, которые обучаются генерировать текста на основе латентного распределения автокодировщиков полученный метод представлен на рис. 10. рисунок 10 – визуализация архитектуры автокодировщика из статьи latent diffusion for language generation

  len(DocSection.structure): 1 DocSection.title: 3.6.1 обучение автокодировщика lvl: 3
  на первом этапе авторы обучает автокодировщик на основе языковой модели, построенной с помощью архитектуру трансформер. эксперименты проводятся с двумя моделями — bart-base [5], обученной командой исследователей из facebook ai и flan-t5-base [6], обученной командой исследователей из google. обе модели основаны на архитектуре трансформер, а значит содержат, как и большинство нейронных сетей, энкодер и декодер. в обычном сценарии работы векторные представления энкодера передаются в декодер, который, на их основе, генерирует новый текст. авторы, с целью получения латентного пространства, добавляют между энкодером и декодером две нейросети — нейросеть сжатия и нейросеть реконструкции. нейросеть сжатия получает на вход векторные представления данных из энкодера, после чего сжимает их. один слой нейросети сжатия состоит из двух блоков — мультиголового механизма самовнимания и сети прямого распространения. архитекутра сети изображена на рис. 11. рисунок 11 – архитектура нейросети сжатия (compression network). e(w) — векторные представления, полученные из энкодера, z — обучаемые query вектора. mha — мультиголовый механизм самовнимания, ff — сеть прямого распространения архитектура нейросети реконструкции совпадает с архитектурой с сети сжатия с точность до размерности матриц так как проекция осуществляется в обратную сторону, из латентного пространства в пространство векторных представлений языковой модели обучение моделей сжатия и реконструкции происходит по следующему алгоритму: 1) полученный текст токенизируется 2) токенизированный текст поступает на вход в энкодер, который генерирует векторные представления 3) векторное представления поступают в сеть сжатия, где переводятся в латентное пространства 4) латенты поступают в сеть реконструкции, где переводятся в исходные векторное представления и поступают в декодер 5) декодер, на основе полученных представлений генерирует вероятностное распределение над токенами 6) зная исходный текст, рассчитывается лосс-функция от исходного текста и полученных распределений. в качестве лосс-функции используется кросс-энтропия 7) с помощью градиентных метод оптимизации веса нейросетей сжатия и реконструкции обновляются. веса энкодера и декодера в ходе обучение заморожены то есть не изменяются
    len(DocSection.structure): 0 DocSection.title: 3.6.2 обучение диффузионной модели lvl: 4
    входе первого этапа авторы получают автокодировщик, который умеет  генерировать латентные представления для текста фиксированного. на втором этапе авторы переходят к обучению диффузионной модели. для набора текстовых данных авторы строят латентные представления, используя полученный автокодировщик. для этого они обучают предиктор шума  для восстановления исходного x, с использованием среднеквадратичной ошибки в качестве лосс-функции: , где x — обучающие данные, t — временной шаг, - случайный гауссовский шум, - означает расписание добавляемого шума, - зависящий от времене коэффициент взвешивания для генерации текста авторы генерируют случайный латентный вектор из стандартного нормального распределения и запускают процесс обратной диффузии используют полученный вектор в качестве при обучении авторы используют косинусное расписание добавляемых коэффициентов: при генерации авторы используют стандартное ddpm [20] расписание и делают 250 временных шагов. в качестве архитектуры предиктора шума используют трансформер с леернормами перед мультиголовыми механизмами внимания с 12 слоями и внутренней размерностью эмбеддингов 768.


  len(DocSection.structure): 2 DocSection.title: 3.7 wav2vec 2.0: a framework for self-supervised learning of speech representations lvl: 3
  в данной работе [23] авторы обучают модель для извлечения эмбеддингов из аудио, содержащих речь, которую затем дообучают на задачу распознавания речи.
    len(DocSection.structure): 0 DocSection.title: 3.7.1 архитектура lvl: 4
    рисунок 12 – архитектура wav2vec 2.0 модель состоит из трёх основных элементов: 1. фича-энкодер - нейросеть для извлечения первичных признаков из аудио и понижения размерности. состоит из нескольких свёрточных слоёв по оси времени, а также леернормов между ними и функций активации gelu. ожидается, что аудио нормализовано и имеет среднее 0 и дисперсию 1. 2. нейросеть контекста, которая получает эмбеддинги из фича-энкодера и строит более высокоуровневые эмбеддинги. архитекутра этой нейросети основывается на трансформере, для кодирования позиционной информации используются свёрточные блоки, похожие на [17], после которых идёт gelu и леернорм 3. модуль квантизации, который дискритизирует выходы фича-энкодера. для квантизации создаётся g кодбуков с v эмбеддингами. далее из каждого кодбука берётся по эмббедингу, они объединются и подаются в линейный слой. для сохранения дифференцируемости этой операции используются софтмакс гумбеля [18] общий вид архитектуры изображён на рис. 12.

    len(DocSection.structure): 0 DocSection.title: 3.7.1 обучение lvl: 4
    фича-энкодер получает на вход исходное аудио x, и на выходе генерирует набор из  представление, где t — количество временных отрезков. далее представления, полученные из фича-энкодера передаются в нейросеть контекста, которая генерирует новые векторные эмбеддинги и используются далее при расчёте лосс функция. для обучения модели в режиме без учителя то есть в отсутствии разметки авторы используют маскирование. целью обучения является определение правильного квантованного представления звука среди набора таких представлений. итоговая лосс функция состоит из двух компонент: первая компонента - - отвечает за правильность классификации квантизованного представления: , где - множество возможноых квантизованных представлений - замаскированное квантизованное представление - векторое представление, полученное из модели - косинусная близость вторая компонента - , так называемая лосс-функция разнообразия и отвечает за увеличения использования представлений из кодбуков. авторы определяют её как задачу максимазации средней энтропии вероятностного распределения над векторами кодбука:


  len(DocSection.structure): 0 DocSection.title: 3.8 предлагаемый подход lvl: 3
  рассмотрев все вышеизложенные публикации можно перейти к описанию подхода, предлагаемого в данной работе. текстовая диффузия с обуславливанием на аудиоэмбеддинги уже была представлена в работе transfusion, однако там использовалась мультиноминальная диффузия т.е диффузия на уровне вероятностного распределения. в то время, как последний публикации в областе диффузионных моделей показывают, что намного эффективней использовать диффузионные модели, действиющие в латентных пространствах.

  len(DocSection.structure): 0 DocSection.title: 3.8.1 обучение автокодировщика lvl: 3
  для обучения диффузионной модели требуется создать автокодировщик текста, в латентном пространстве которого будет работать модель. подходящий автокодировщик уже был разобран выше при рассмотрении статьи latent diffusion for language generation. осталось лишь обучить такой автокодировщик на домене транскрипций. основной для обучения автокодировщика послужит модель от компании facebook ai — bart-base.

  len(DocSection.structure): 1 DocSection.title: 3.8.2 получение эмбеддингов для аудио lvl: 3
  на данный момент, одной из лучших и популярнейших моделей в области получения эмбеддингов является предобученный wav2vec2.0 от компании facebook ai, архитектура и принцип работы которого также рассмотрены выше. в данной работе используется версия wav2vec2.0-large.
    len(DocSection.structure): 0 DocSection.title: 3.8.3 обучение диффузионной модели lvl: 4
    в качестве архитекутры предсказателя шума был выбран трансформер с пре-леернормами (то есть нормировка производится перед механизмом внимания), что позволяет улучшить стабильность и сходимость модели. для построения эмбеддингов временного шага используются синусоидальные абсолютные эмбеддинги: для кодирования позиционной информации аудио эмбеддингов используется относительный позиционный кодировщик, основанный на обучаемых свёртках. в качестве лосс-функции используется среднеквадратичная ошибка между шумом, добавленным в ходе прямого процесса диффузии и шумом предсказанным в ходе обратного на каждой итерации. на обучении используется ddpm расписание добавления шума c 200 временных шагов.



len(DocSection.structure): 3 DocSection.title: 4. практическая часть lvl: 2

  len(DocSection.structure): 0 DocSection.title: 4.1 используемые инструменты и библиотеки lvl: 3
  для написания кода и последующего проведения экспериментов был использован ряд фреймворков и библиотеки: pytorch — самый популярный фреймворк для глубокого обучения, который содержит в себе абстракции для тензорных вычислений, автоматического дифференцирования, вычислений на cuda и ряд реализаций типовых слоёв нейронных сетей и многое другое [11]. transformers — фреймворк для глубокого обучения, разработанный компанией huggingface, содержащий большое количество реализаций современных архитектур нейронных сетей и предобученных моделей, основанных на архитектуре трансформер [12]. diffusers — фреймворк для глубокого обучения, разработанный компанией huggingface, содержащий большое количество реализаций современных архитектур нейронных сетей и предобученных моделей, основанных на диффузионных моделях [13]. accelerate — фреймворк для ускорения обучения нейронных сетей, разработанный компанией huggingface, содержит ряд абстракций для упрощения обучения в distribureddataparallel (параллелизм по графическим процессорам) режиме, облегчает работу с перемещением данных между оперативной памятью и памятью графического процессов, оптимизирует вычисления [14].

  len(DocSection.structure): 0 DocSection.title: 4.2 описание данных lvl: 3
  в рамках данной работы был использован корпус данных librispeech-960h [10], который содержит 960 часов размеченной английской речи из аудиокниг для обучения,  большая часть книг взята из проекта «гутенберг». также в корпусе есть несколько валидационных сетов, которые разделены на две категории - «чистые» и «прочие», в зависимости от качества условий записи. каждый из валидационных сетов содержит примерно 5 часов человеческой речи. исходные аудио представлены в формате .flac c частотой 16 килогерц в виде моноканальных канальных записей.

  len(DocSection.structure): 4 DocSection.title: 4.3 описание экспериментов lvl: 3
  эксперименты проводились на 8 графических процессорах nvidia a100-pcie-40gb. обучение происходило на датасете librispeech-960h. для обучения автокодировщика использовались референсные транскрипции, а для обучения диффузионной модели эмбеддинги аудио из wav2vec2.0-large и эмбеддинги текста из обученного автокодировщика.
    len(DocSection.structure): 0 DocSection.title: 4.3.1 обучение автокодировщика текста lvl: 4
    был проведён ряд экспериментов по обучению автокодировщика текста с различными параметрами. параметры при обучении нейросети сжатия: 3 скрытых слоя оптимизатор adamw с  бетами (0.9, 0.999) линейное расписание коэффциентов обучения размер батча 365 общее количество итераций 50000 количество итераций разгогрева  1000 пиковое значение коэффициента обучение 1e-5 параметры при обучении нейросети реконструкции: 3 скрытых слоя оптимизатор adamw с бетами (0.9, 0.999) линейное расписание коэффциентов обучения размер батча 365 общее количество итераций 50000 количество итераций разгогрева  1000 пиковое значение коэффициента обучение 1e-5 в качестве предобученной языковой модели использовался bart-base от компании facebook ai. результаты экспериментов представлены в таблице 1. таблица 1 – значение метрик для автокодировщика

    len(DocSection.structure): 0 DocSection.title: 4.3.2 получение векторных представлений аудио lvl: 4
    для получения векторых представлений использовалась модель wav2vec2.0-large от компании facebook ai.

    len(DocSection.structure): 0 DocSection.title: 4.3.3 обучение предсказателя шума lvl: 4
    после получения аудиоэмбеддингов и обучения автокодировщиках становится возможным обучить диффузионную модель. на вход модель получает текущее латентное представление текста, аудиоэмбеддинг и номер шага диффузии. архитектура представляет собой трансформер с пре-леернормами и кросс-аттеншеном на части слоёв между внутренними представлениями сети и аудиоэмбеддингами. для эмбеддингов аудио используются обучаемые относительные позиционные эмбеддинги из [17] с параметрами conv_pos = 32, conv_pos_groups = 4. для эмбеддингов аудио используются абсолютные синусоидальные эмбеддинги с параметрами t_emb_dim = 768, t_emb_max_period = 1000. по полученным эмбеддингам и информации о временном шаге диффузии модель предсказывает шум. исходя из значений предсказаний и истинных значений добавленного шума расчитывается среднеквадратичная ошибка, а далее происходит минимизация данной ошибки. параметры обучения: 24 трансформер-блока оптимизатор adamw с бетами (0.9, 0.999) линейное расписание коэффициентов обучения размер батча 500 общее количество итераций 700k количество итераций разгогрева  30000 пиковое значение коэффициента обучения 3e-5

    len(DocSection.structure): 0 DocSection.title: 4.3.4 оценка и сравнения полученной модели lvl: 4
    оценка проводилась на валидационных датасетах из корпуса librispeech, значение метрик для transfusion и conformer были взяты из статей. результаты экспериментов представлены в таблице 2. таблица 2 – значение wer на валидационных датасетах результаты для conformer указаны с учётом применения языковой модели для последующей переоценки возможных транскрипций. для объяснения причин таких низких метрик можно рассмотреть кривые обучения. рисунок 13 – график лосс функции на обучении предиктора шума рисунок 14 – график метрики rougelsum на валидацци при обучении автокодировщика исходя из графика на рис. 13 можно сделать вывод о том, что автокодировщик хорошо выполняет задачу восстановления и почти не теряет данные, однако это ничего не говорит об организации его латентного пространства. вместе с тем на рис. 14 видно, что при обучении предиктора шума лосс-функции быстро выходит на плато на уровне 0.2 и начинает там осциллировать, также видно, что кривая лосс-функции довольно шумная. так как процесс диффузии происходит в латеном пространстве автокодировщика можно сделать вывод о том, что оно устроено слишком сложно и предиктор шума не может достаточно хорошо оценить добавленный шум.



len(DocSection.structure): 4 DocSection.title: 5. обеспечение качества разработки, продукции, программного продукта lvl: 2

  len(DocSection.structure): 0 DocSection.title: 5.1 определение потребителей lvl: 3
  потребителями разработанной модели могут быть: компании, разрабатывающие системы видеоконфенцсвязи, использующие системы распознавания речи для транскрибации прошедших встреч компании, разрабатывающие системы речевой аналитики, использующие системы распознавания речи для транскрибации звонков и последующего анализа текстов компании, разрабатывающие голосовых помощников, использующие системы распознавания речи для распознавания команд и запросов пользователя

  len(DocSection.structure): 0 DocSection.title: 5.2 функции продукции lvl: 3
  для того, чтобы ответить на вопрос, какие функции имеет, разработанный продукт, необходимо ввести определение функции изделия или услуги. функции изделия или услуги – это требования и ожидания потребителя, которые могут быть установлены, предполагаются или являются обязательными. перечень пользовательских требования к разработанной системе: пользователь должен получать результат распознавания речи пользователю должна предоставляться оценка качества модели по метрике wer на размеченных данных

  len(DocSection.structure): 0 DocSection.title: 5.3 качество и характеристики lvl: 3
  для обеспечения качества разрабатываемой системы был проведен обзор стандартов, протоколов, отраслевых требований и современных лучших практик, нужных в разработке. при этом качество – степень соответствия совокупности присущих характеристик объекта требованиям (согласно гост р исо 9000-2015). знание протоколов, стандартов и пр. позволяет обеспечить соответсвие системы современным требования, повысить эффективность и удобство использования. анализ функциональных требований к разработке отражён в таблице 3. таблица 3 – функциональные требования

  len(DocSection.structure): 0 DocSection.title: 5.4 измерение характеристик качества. операциональное определение lvl: 3
  операциональное определение (оо) – это уточнение значения того или иного термина применительно к данной системе, находящейся в конкретных условиях и для людей, в ней задействованных. оо необходим для уменьшения случаев разночтения и неоднозначности при общении между людьми, задействованными в системе, а также для более точного определения целей и задач, которые необходимо достичь. оо должно содержать как минимум три компоненты: требования или стандарт, относительно которого оценивается результат измерения или испытания (критерий). метод испытания или процедура измерения свойства объекта (тест) процедура принятия решения (анализ), которое показывает, соответствует ли результат испытания стандарту. операциональные определения для разработанной модели описаны в таблице 4. по итогам рассмотрения оперциональных опеределений было установлена, что разработанная модель не удовлетворяет описанным требования, однако существует ряд предложений по улучшению, сформированных в таблице 5 таблица 5 — предложения по улучшению модели.


len(DocSection.structure): 0 DocSection.title: заключение lvl: 2
в рамках данной работы был проведён анализ существующих решений, рассмотрен подход к диффузионным моделям в задаче распознавания речи из статьи transfusion. далее были изучены актуальные методы для генерации текста с помощью текстовой диффузии и её обуславливания на информацию из аудио. после выбора метода была реализована диффузионная модель для генерации текста на основе аудиоэмбеддинга. данная модель использует текстовый автокодировщик для получения латентных представлений текста, которые используются в диффузии. для полученной модели была проведена оценка качества и сравнение с аналогами на основе валидационных датасетов из корпуса librispeech-960h в результате работы была провена гипотеза о применимости диффузионных моделей на непрерывных представлениях в задаче распознавания речи. результатом проверки гипотезы стал вывод о неприменимости данного подхода из-за плохого качества. для улучшения качества имеет смысл используются другие способы получения латентного пространства, такие как вариационный автоэнкодер или flow-matching.

